{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMFQfaZer8VuZslkly3GfAK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "90TTTD-1r_cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLabiJQbovRp",
        "outputId": "6bfb9a9c-6908-41eb-e940-8adb2f54690c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "77AGBww6r55b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071e6140-ebf2-44c8-c7d7-6a505b87e2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting FLAVA Multi-scale Ablation Study...\n",
            "This will train 5 different model configurations to analyze scale contributions.\n",
            "Found 522 images with masks\n",
            "Dataset: 417 train, 105 val samples\n",
            "\n",
            "==================================================\n",
            "Training full_multiscale: All three scales\n",
            "Active scales: [1, 2, 3]\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/8: 100%|██████████| 105/105 [05:33<00:00,  3.17s/it]\n",
            "Evaluating: 100%|██████████| 27/27 [01:13<00:00,  2.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train IoU: 0.4679, Val IoU: 0.5250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/8: 100%|██████████| 105/105 [00:25<00:00,  4.15it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train IoU: 0.5956, Val IoU: 0.6063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/8: 100%|██████████| 105/105 [00:24<00:00,  4.27it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train IoU: 0.6595, Val IoU: 0.6224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/8: 100%|██████████| 105/105 [00:25<00:00,  4.07it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train IoU: 0.6896, Val IoU: 0.6619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/8: 100%|██████████| 105/105 [00:25<00:00,  4.09it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  7.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train IoU: 0.7165, Val IoU: 0.6625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/8: 100%|██████████| 105/105 [00:25<00:00,  4.14it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train IoU: 0.7330, Val IoU: 0.6855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/8: 100%|██████████| 105/105 [00:25<00:00,  4.12it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train IoU: 0.7415, Val IoU: 0.6904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/8: 100%|██████████| 105/105 [00:25<00:00,  4.19it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train IoU: 0.7500, Val IoU: 0.6760\n",
            "✅ full_multiscale: Best IoU = 0.6904\n",
            "\n",
            "==================================================\n",
            "Training without_scale1: Medium + Coarse (no fine details)\n",
            "Active scales: [2, 3]\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/8: 100%|██████████| 105/105 [00:24<00:00,  4.23it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train IoU: 0.3980, Val IoU: 0.4117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/8: 100%|██████████| 105/105 [00:24<00:00,  4.25it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train IoU: 0.5393, Val IoU: 0.5933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/8: 100%|██████████| 105/105 [00:25<00:00,  4.12it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train IoU: 0.5765, Val IoU: 0.5693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/8: 100%|██████████| 105/105 [00:25<00:00,  4.18it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train IoU: 0.6227, Val IoU: 0.5257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/8: 100%|██████████| 105/105 [00:24<00:00,  4.27it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train IoU: 0.6390, Val IoU: 0.6022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/8: 100%|██████████| 105/105 [00:24<00:00,  4.26it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train IoU: 0.6553, Val IoU: 0.6077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/8: 100%|██████████| 105/105 [00:24<00:00,  4.22it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train IoU: 0.6725, Val IoU: 0.6054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/8: 100%|██████████| 105/105 [00:24<00:00,  4.22it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train IoU: 0.6816, Val IoU: 0.6142\n",
            "✅ without_scale1: Best IoU = 0.6142\n",
            "\n",
            "==================================================\n",
            "Training without_scale2: Fine + Coarse (no medium scale)\n",
            "Active scales: [1, 3]\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/8: 100%|██████████| 105/105 [00:24<00:00,  4.21it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train IoU: 0.4655, Val IoU: 0.5069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/8: 100%|██████████| 105/105 [00:25<00:00,  4.11it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train IoU: 0.5994, Val IoU: 0.6466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/8: 100%|██████████| 105/105 [00:25<00:00,  4.18it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train IoU: 0.6747, Val IoU: 0.6323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/8: 100%|██████████| 105/105 [00:25<00:00,  4.17it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train IoU: 0.7095, Val IoU: 0.6403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/8: 100%|██████████| 105/105 [00:24<00:00,  4.22it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train IoU: 0.7291, Val IoU: 0.6752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/8: 100%|██████████| 105/105 [00:24<00:00,  4.26it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  7.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train IoU: 0.7364, Val IoU: 0.6743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/8: 100%|██████████| 105/105 [00:24<00:00,  4.25it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train IoU: 0.7484, Val IoU: 0.6746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/8: 100%|██████████| 105/105 [00:25<00:00,  4.18it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train IoU: 0.7496, Val IoU: 0.7124\n",
            "✅ without_scale2: Best IoU = 0.7124\n",
            "\n",
            "==================================================\n",
            "Training without_scale3: Fine + Medium (no global context)\n",
            "Active scales: [1, 2]\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/8: 100%|██████████| 105/105 [00:25<00:00,  4.13it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train IoU: 0.5075, Val IoU: 0.5883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/8: 100%|██████████| 105/105 [00:25<00:00,  4.16it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train IoU: 0.6233, Val IoU: 0.6673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/8: 100%|██████████| 105/105 [00:24<00:00,  4.24it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train IoU: 0.6926, Val IoU: 0.6772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/8: 100%|██████████| 105/105 [00:24<00:00,  4.24it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train IoU: 0.7231, Val IoU: 0.6765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/8: 100%|██████████| 105/105 [00:24<00:00,  4.26it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train IoU: 0.7337, Val IoU: 0.6791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/8: 100%|██████████| 105/105 [00:24<00:00,  4.21it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train IoU: 0.7425, Val IoU: 0.6863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/8: 100%|██████████| 105/105 [00:24<00:00,  4.20it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train IoU: 0.7477, Val IoU: 0.6872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/8: 100%|██████████| 105/105 [00:24<00:00,  4.33it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  7.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train IoU: 0.7499, Val IoU: 0.7047\n",
            "✅ without_scale3: Best IoU = 0.7047\n",
            "\n",
            "==================================================\n",
            "Training single_scale: Only original scale\n",
            "Active scales: [1]\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/8: 100%|██████████| 105/105 [00:24<00:00,  4.24it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train IoU: 0.4931, Val IoU: 0.5861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/8: 100%|██████████| 105/105 [00:24<00:00,  4.23it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train IoU: 0.6354, Val IoU: 0.6171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/8: 100%|██████████| 105/105 [00:24<00:00,  4.23it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train IoU: 0.6886, Val IoU: 0.6335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/8: 100%|██████████| 105/105 [00:28<00:00,  3.71it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train IoU: 0.7007, Val IoU: 0.6280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/8: 100%|██████████| 105/105 [00:25<00:00,  4.14it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train IoU: 0.7294, Val IoU: 0.6627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/8: 100%|██████████| 105/105 [00:24<00:00,  4.32it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train IoU: 0.7302, Val IoU: 0.6651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/8: 100%|██████████| 105/105 [00:25<00:00,  4.18it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  7.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train IoU: 0.7395, Val IoU: 0.6639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/8: 100%|██████████| 105/105 [00:24<00:00,  4.29it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train IoU: 0.7500, Val IoU: 0.6704\n",
            "✅ single_scale: Best IoU = 0.6704\n",
            "\n",
            "============================================================\n",
            "MULTI-SCALE FEATURE CONTRIBUTION ANALYSIS\n",
            "============================================================\n",
            "Baseline (Full Multi-scale): 0.6904 IoU\n",
            "------------------------------------------------------------\n",
            "without_scale1       | 0.6142 IoU | -0.0762 (11.0% reduction)\n",
            "                     | Medium + Coarse (no fine details)\n",
            "------------------------------------------------------------\n",
            "without_scale2       | 0.7124 IoU | --0.0220 (-3.2% reduction)\n",
            "                     | Fine + Coarse (no medium scale)\n",
            "------------------------------------------------------------\n",
            "without_scale3       | 0.7047 IoU | --0.0143 (-2.1% reduction)\n",
            "                     | Fine + Medium (no global context)\n",
            "------------------------------------------------------------\n",
            "single_scale         | 0.6704 IoU | -0.0200 (2.9% reduction)\n",
            "                     | Only original scale\n",
            "------------------------------------------------------------\n",
            "\n",
            "✅ Ablation study completed successfully!\n",
            "📊 Results saved to: /content/drive/MyDrive/Colab Notebooks/YOLO/YOLO12Result/ablation study/ablation_results\n",
            "📈 Visualizations and detailed report generated\n",
            "\n",
            "================================================================================\n",
            "SUMMARY FOR PAPER - MULTI-SCALE FEATURE CONTRIBUTION\n",
            "================================================================================\n",
            "**Feature Scale Analysis:**\n",
            "* Scale 1 (Original): Primary contribution to fine boundary delineation\n",
            "* Scale 2 (Medium): Important for medium-sized defect detection\n",
            "* Scale 3 (Coarse): Critical for global context and large defect identification\n",
            "\n",
            "**Ablation Study Results:**\n",
            "Systematic removal of each scale demonstrates complementary contributions:\n",
            "* Without Scale 1: 11.0% IoU reduction, poor boundary precision\n",
            "* Without Scale 2: -3.2% IoU reduction, missed medium defects\n",
            "* Without Scale 3: -2.1% IoU reduction, poor global context integration\n",
            "\n",
            "Baseline Performance: 0.6904 IoU\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Enhanced FLAVA Defect Segmentation with Multi-scale Ablation Study\n",
        "# This code includes a comprehensive ablation study to analyze the contribution of each scale\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Resize\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import FlavaModel, FlavaProcessor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "from scipy.stats import ttest_ind, pearsonr\n",
        "\n",
        "# ==== CONFIG ====\n",
        "class Config:\n",
        "\n",
        "    base_model_path = \"/content/drive/MyDrive/Colab Notebooks/YOLO/YOLO12Result/outputs_flava/flava_finetuned\"\n",
        "    data_path = \"/content/drive/MyDrive/Colab Notebooks/YOLO/YOLO12Result/Data12 class segmentation\"\n",
        "    save_path = \"/content/drive/MyDrive/Colab Notebooks/YOLO/YOLO12Result/ablation study\"\n",
        "    debug_dir = os.path.join(save_path, \"debug\")\n",
        "    plots_dir = os.path.join(save_path, \"plots\")\n",
        "    metrics_dir = os.path.join(save_path, \"metrics\")\n",
        "    ablation_dir = os.path.join(save_path, \"ablation_results\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    batch_size = 4\n",
        "    num_epochs = 8  # Reduced for ablation study\n",
        "    lr = 2e-5\n",
        "    patch_grid = 14\n",
        "    mask_size = (14, 14)\n",
        "    test_split = 0.2\n",
        "    # Multi-scale configurations for ablation study\n",
        "    ablation_configs = [\n",
        "        {'name': 'full_multiscale', 'scales': [1, 2, 3], 'description': 'All three scales'},\n",
        "        {'name': 'without_scale1', 'scales': [2, 3], 'description': 'Medium + Coarse (no fine details)'},\n",
        "        {'name': 'without_scale2', 'scales': [1, 3], 'description': 'Fine + Coarse (no medium scale)'},\n",
        "        {'name': 'without_scale3', 'scales': [1, 2], 'description': 'Fine + Medium (no global context)'},\n",
        "        {'name': 'single_scale', 'scales': [1], 'description': 'Only original scale'},\n",
        "    ]\n",
        "\n",
        "# Create necessary directories\n",
        "for directory in [Config.save_path, Config.debug_dir, Config.plots_dir, Config.metrics_dir, Config.ablation_dir]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "print(f\"Using device: {Config.device}\")\n",
        "\n",
        "# ==== DATASET ====\n",
        "class MaskedDataset(Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.imgs, self.masks = [], []\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        self.mask_resize = Resize(Config.mask_size)\n",
        "\n",
        "        for cls in os.listdir(data_dir):\n",
        "            p = os.path.join(data_dir, cls)\n",
        "            if not os.path.isdir(p): continue\n",
        "            for f in os.listdir(p):\n",
        "                if f.endswith(\".json\"):\n",
        "                    img = os.path.join(p, f.replace(\".json\", \".jpg\"))\n",
        "                    jsn = os.path.join(p, f)\n",
        "                    if os.path.exists(img):\n",
        "                        self.imgs.append(img)\n",
        "                        self.masks.append(jsn)\n",
        "\n",
        "        print(f\"Found {len(self.imgs)} images with masks\")\n",
        "\n",
        "    def __len__(self): return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open(self.imgs[i]).convert(\"RGB\")\n",
        "        img_tensor = self.img_transform(img)\n",
        "\n",
        "        mask_arr = np.zeros((640, 640), dtype=np.uint8)\n",
        "        with open(self.masks[i]) as f:\n",
        "            data = json.load(f)\n",
        "            for ann in data.get('annotations', []):\n",
        "                x, y, w, h = map(int, ann['bbox'])\n",
        "                x2, y2 = min(x+w, 640), min(y+h, 640)\n",
        "                mask_arr[y:y2, x:x2] = 1\n",
        "        mask = self.mask_resize(Image.fromarray(mask_arr * 255))\n",
        "        mask_tensor = transforms.ToTensor()(mask).float().squeeze(0)\n",
        "\n",
        "        return img_tensor, mask_tensor, self.imgs[i]\n",
        "\n",
        "# ==== LOSS FUNCTION ====\n",
        "class FocalDiceLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.5, gamma=2.0, beta=0.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
        "            inputs, targets, reduction='none'\n",
        "        )\n",
        "        probs = torch.sigmoid(inputs)\n",
        "        pt = torch.where(targets == 1, probs, 1-probs)\n",
        "        focal_weight = (1-pt) ** self.gamma\n",
        "        focal_loss = focal_weight * bce_loss\n",
        "\n",
        "        inputs_sigmoid = torch.sigmoid(inputs)\n",
        "        intersection = (inputs_sigmoid * targets).sum((1,2))\n",
        "        union = (inputs_sigmoid + targets).sum((1,2))\n",
        "        dice_loss = 1 - (2. * intersection + 1e-6) / (union + 1e-6)\n",
        "\n",
        "        combined_loss = self.beta * focal_loss.mean() + (1-self.beta) * dice_loss.mean()\n",
        "        return combined_loss\n",
        "\n",
        "# ==== CONFIGURABLE SEGMENTATION HEAD ====\n",
        "class ConfigurableFLAVASegmenter(nn.Module):\n",
        "    def __init__(self, base_model_path, active_scales=[1, 2, 3]):\n",
        "        super().__init__()\n",
        "        self.model = FlavaModel.from_pretrained(base_model_path)\n",
        "        self.active_scales = active_scales\n",
        "\n",
        "        # Projection for original scale\n",
        "        self.syn_projection = nn.Linear(self.model.config.hidden_size, 256)\n",
        "\n",
        "        # Calculate number of output channels based on active scales\n",
        "        num_channels = len(active_scales) * 256\n",
        "\n",
        "        # Fusion for multi-scale features\n",
        "        self.fusion = nn.Conv2d(num_channels, 256, kernel_size=1)\n",
        "\n",
        "        # Segmentation head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def create_multi_scale_features(self, embeddings):\n",
        "        \"\"\"Create multi-scale features based on active_scales configuration\"\"\"\n",
        "        b, n, c = embeddings.shape\n",
        "        projected = self.syn_projection(embeddings)\n",
        "        spatial = projected.reshape(b, Config.patch_grid, Config.patch_grid, -1).permute(0, 3, 1, 2)\n",
        "\n",
        "        features = []\n",
        "\n",
        "        for scale in self.active_scales:\n",
        "            if scale == 1:\n",
        "                # Original scale (fine details)\n",
        "                features.append(spatial)\n",
        "            elif scale == 2:\n",
        "                # Medium scale (2x2 pooling)\n",
        "                pooled = F.avg_pool2d(spatial, kernel_size=2, stride=2)\n",
        "                upsampled = F.interpolate(pooled, size=(Config.patch_grid, Config.patch_grid),\n",
        "                                        mode='bilinear', align_corners=False)\n",
        "                features.append(upsampled)\n",
        "            elif scale == 3:\n",
        "                # Coarse scale (4x4 pooling for global context)\n",
        "                pooled = F.avg_pool2d(spatial, kernel_size=4, stride=4)\n",
        "                upsampled = F.interpolate(pooled, size=(Config.patch_grid, Config.patch_grid),\n",
        "                                        mode='bilinear', align_corners=False)\n",
        "                features.append(upsampled)\n",
        "\n",
        "        # Concatenate active scales\n",
        "        multi_scale = torch.cat(features, dim=1)\n",
        "        fused = self.fusion(multi_scale)\n",
        "        return fused\n",
        "\n",
        "    def forward(self, pixel_inputs):\n",
        "        outputs = self.model(pixel_values=pixel_inputs)\n",
        "        patches = outputs.image_embeddings[:, 1:, :]  # Skip CLS token\n",
        "        fused_features = self.create_multi_scale_features(patches)\n",
        "        seg_logits = self.head(fused_features)\n",
        "        return seg_logits\n",
        "\n",
        "# ==== EVALUATION FUNCTIONS ====\n",
        "def calculate_metrics(preds, masks):\n",
        "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
        "    intersection = (preds * masks).sum((1,2))\n",
        "    union = ((preds + masks) >= 1).float().sum((1,2))\n",
        "    batch_iou = (intersection / (union + 1e-6))\n",
        "\n",
        "    dice = (2 * intersection) / (preds.sum((1,2)) + masks.sum((1,2)) + 1e-6)\n",
        "\n",
        "    tp = (preds * masks).sum((1,2))\n",
        "    fp = (preds * (1-masks)).sum((1,2))\n",
        "    fn = ((1-preds) * masks).sum((1,2))\n",
        "    tn = ((1-preds) * (1-masks)).sum((1,2))\n",
        "\n",
        "    precision = tp / (tp + fp + 1e-6)\n",
        "    recall = tp / (tp + fn + 1e-6)\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-6)\n",
        "    specificity = tn / (tn + fp + 1e-6)\n",
        "\n",
        "    metrics = {\n",
        "        'iou': batch_iou.mean().item(),\n",
        "        'dice': dice.mean().item(),\n",
        "        'precision': precision.mean().item(),\n",
        "        'recall': recall.mean().item(),\n",
        "        'f1': f1.mean().item(),\n",
        "        'accuracy': accuracy.mean().item(),\n",
        "        'specificity': specificity.mean().item()\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def evaluate_model(model, dataloader, processor):\n",
        "    \"\"\"Evaluate model on a dataset\"\"\"\n",
        "    model.eval()\n",
        "    all_metrics = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks, _ in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            imgs, masks = imgs.to(Config.device), masks.to(Config.device)\n",
        "            pixel_inputs = processor(images=imgs, return_tensors=\"pt\")[\"pixel_values\"].to(Config.device)\n",
        "\n",
        "            logits = model(pixel_inputs).squeeze(1)\n",
        "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
        "\n",
        "            batch_metrics = calculate_metrics(preds, masks)\n",
        "            all_metrics.append(batch_metrics)\n",
        "\n",
        "    results = {}\n",
        "    for metric in all_metrics[0].keys():\n",
        "        results[metric] = np.mean([m[metric] for m in all_metrics])\n",
        "\n",
        "    return results\n",
        "\n",
        "# ==== TRAINING FUNCTION ====\n",
        "def train_model(config_name, active_scales, train_loader, val_loader, processor):\n",
        "    \"\"\"Train a model with specific scale configuration\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {config_name}: {Config.ablation_configs[[c['name'] for c in Config.ablation_configs].index(config_name)]['description']}\")\n",
        "    print(f\"Active scales: {active_scales}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    model = ConfigurableFLAVASegmenter(Config.base_model_path, active_scales).to(Config.device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=Config.lr)\n",
        "    loss_fn = FocalDiceLoss()\n",
        "\n",
        "    best_val_iou = 0\n",
        "    metrics_history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_iou': [], 'val_iou': [],\n",
        "        'train_dice': [], 'val_dice': [],\n",
        "        'train_f1': [], 'val_f1': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(Config.num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        train_metrics_list = []\n",
        "\n",
        "        for imgs, masks, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config.num_epochs}\"):\n",
        "            imgs, masks = imgs.to(Config.device), masks.to(Config.device)\n",
        "            pixel_inputs = processor(images=imgs, return_tensors=\"pt\")[\"pixel_values\"].to(Config.device)\n",
        "\n",
        "            logits = model(pixel_inputs).squeeze(1)\n",
        "            loss = loss_fn(logits, masks)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
        "            batch_metrics = calculate_metrics(preds, masks)\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            train_metrics_list.append(batch_metrics)\n",
        "\n",
        "        # Validation phase\n",
        "        val_metrics = evaluate_model(model, val_loader, processor)\n",
        "\n",
        "        # Calculate averages\n",
        "        avg_train_loss = np.mean(train_losses)\n",
        "        avg_train_metrics = {}\n",
        "        for metric in train_metrics_list[0].keys():\n",
        "            avg_train_metrics[metric] = np.mean([m[metric] for m in train_metrics_list])\n",
        "\n",
        "        # Update history\n",
        "        metrics_history['train_loss'].append(avg_train_loss)\n",
        "        metrics_history['val_loss'].append(0)  # Not computing val loss for efficiency\n",
        "\n",
        "        for metric in ['iou', 'dice', 'f1']:\n",
        "            metrics_history[f'train_{metric}'].append(avg_train_metrics[metric])\n",
        "            metrics_history[f'val_{metric}'].append(val_metrics[metric])\n",
        "\n",
        "        # Save best model\n",
        "        if val_metrics['iou'] > best_val_iou:\n",
        "            best_val_iou = val_metrics['iou']\n",
        "            torch.save(model.state_dict(),\n",
        "                      os.path.join(Config.save_path, f\"best_model_{config_name}.pth\"))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train IoU: {avg_train_metrics['iou']:.4f}, Val IoU: {val_metrics['iou']:.4f}\")\n",
        "\n",
        "    return model, metrics_history, best_val_iou\n",
        "\n",
        "# ==== ABLATION STUDY ====\n",
        "def run_ablation_study():\n",
        "    \"\"\"Run complete ablation study\"\"\"\n",
        "    # Load dataset\n",
        "    full_dataset = MaskedDataset(Config.data_path)\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        range(len(full_dataset)), test_size=Config.test_split, random_state=42\n",
        "    )\n",
        "\n",
        "    train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
        "    val_dataset = torch.utils.data.Subset(full_dataset, val_indices)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=Config.batch_size, shuffle=False)\n",
        "\n",
        "    processor = FlavaProcessor.from_pretrained(Config.base_model_path)\n",
        "    processor.image_processor.do_rescale = False\n",
        "\n",
        "    print(f\"Dataset: {len(train_dataset)} train, {len(val_dataset)} val samples\")\n",
        "\n",
        "    # Results storage\n",
        "    ablation_results = {}\n",
        "\n",
        "    # Train each configuration\n",
        "    for config in Config.ablation_configs:\n",
        "        model, history, best_iou = train_model(\n",
        "            config['name'],\n",
        "            config['scales'],\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            processor\n",
        "        )\n",
        "\n",
        "        # Store results\n",
        "        ablation_results[config['name']] = {\n",
        "            'description': config['description'],\n",
        "            'scales': config['scales'],\n",
        "            'best_val_iou': best_iou,\n",
        "            'final_val_iou': history['val_iou'][-1] if history['val_iou'] else 0,\n",
        "            'history': history\n",
        "        }\n",
        "\n",
        "        print(f\"✅ {config['name']}: Best IoU = {best_iou:.4f}\")\n",
        "\n",
        "    return ablation_results\n",
        "\n",
        "# ==== ANALYSIS AND VISUALIZATION ====\n",
        "def analyze_ablation_results(results):\n",
        "    \"\"\"Analyze and visualize ablation study results\"\"\"\n",
        "\n",
        "    # Extract key metrics\n",
        "    config_names = []\n",
        "    descriptions = []\n",
        "    iou_scores = []\n",
        "    scale_configs = []\n",
        "\n",
        "    for name, data in results.items():\n",
        "        config_names.append(name)\n",
        "        descriptions.append(data['description'])\n",
        "        iou_scores.append(data['best_val_iou'])\n",
        "        scale_configs.append(data['scales'])\n",
        "\n",
        "    # Create results dataframe\n",
        "    results_df = pd.DataFrame({\n",
        "        'Configuration': config_names,\n",
        "        'Description': descriptions,\n",
        "        'IoU': iou_scores,\n",
        "        'Scales': scale_configs\n",
        "    })\n",
        "\n",
        "    # Save results\n",
        "    results_df.to_csv(os.path.join(Config.ablation_dir, \"ablation_results.csv\"), index=False)\n",
        "\n",
        "    # Calculate IoU reductions relative to full multi-scale\n",
        "    baseline_iou = results['full_multiscale']['best_val_iou']\n",
        "\n",
        "    reductions = {}\n",
        "    for name, data in results.items():\n",
        "        if name != 'full_multiscale':\n",
        "            reduction = baseline_iou - data['best_val_iou']\n",
        "            reduction_pct = (reduction / baseline_iou) * 100\n",
        "            reductions[name] = {\n",
        "                'absolute_reduction': reduction,\n",
        "                'percentage_reduction': reduction_pct\n",
        "            }\n",
        "\n",
        "    # Print detailed analysis\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"MULTI-SCALE FEATURE CONTRIBUTION ANALYSIS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Baseline (Full Multi-scale): {baseline_iou:.4f} IoU\")\n",
        "    print(f\"{'-'*60}\")\n",
        "\n",
        "    for name, reduction_data in reductions.items():\n",
        "        config_desc = results[name]['description']\n",
        "        current_iou = results[name]['best_val_iou']\n",
        "        abs_red = reduction_data['absolute_reduction']\n",
        "        pct_red = reduction_data['percentage_reduction']\n",
        "\n",
        "        print(f\"{name:20s} | {current_iou:.4f} IoU | -{abs_red:.4f} ({pct_red:.1f}% reduction)\")\n",
        "        print(f\"                     | {config_desc}\")\n",
        "        print(f\"{'-'*60}\")\n",
        "\n",
        "    # Create visualizations\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # 1. Bar plot of IoU scores\n",
        "    plt.subplot(2, 2, 1)\n",
        "    bars = plt.bar(range(len(config_names)), iou_scores,\n",
        "                   color=['green' if name == 'full_multiscale' else 'steelblue' for name in config_names])\n",
        "    plt.xticks(range(len(config_names)), [name.replace('_', '\\n') for name in config_names], rotation=45)\n",
        "    plt.ylabel('IoU Score')\n",
        "    plt.title('IoU Performance by Configuration')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, score in zip(bars, iou_scores):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
        "                f'{score:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    # 2. IoU reduction analysis\n",
        "    plt.subplot(2, 2, 2)\n",
        "    reduction_names = list(reductions.keys())\n",
        "    reduction_values = [reductions[name]['percentage_reduction'] for name in reduction_names]\n",
        "\n",
        "    bars = plt.bar(range(len(reduction_names)), reduction_values, color='coral')\n",
        "    plt.xticks(range(len(reduction_names)), [name.replace('_', '\\n') for name in reduction_names], rotation=45)\n",
        "    plt.ylabel('IoU Reduction (%)')\n",
        "    plt.title('Performance Drop When Removing Scales')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add value labels\n",
        "    for bar, value in zip(bars, reduction_values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
        "                f'{value:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "    # 3. Training curves comparison\n",
        "    plt.subplot(2, 2, 3)\n",
        "    for name, data in results.items():\n",
        "        if 'val_iou' in data['history'] and data['history']['val_iou']:\n",
        "            epochs = range(1, len(data['history']['val_iou']) + 1)\n",
        "            plt.plot(epochs, data['history']['val_iou'], label=name, marker='o', linewidth=2)\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Validation IoU')\n",
        "    plt.title('Training Progress Comparison')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. Scale contribution heatmap\n",
        "    plt.subplot(2, 2, 4)\n",
        "    scale_matrix = np.zeros((len(config_names), 3))  # 3 scales\n",
        "    for i, scales in enumerate(scale_configs):\n",
        "        for scale in scales:\n",
        "            scale_matrix[i, scale-1] = 1\n",
        "\n",
        "    im = plt.imshow(scale_matrix, cmap='RdYlBu_r', aspect='auto')\n",
        "    plt.xticks([0, 1, 2], ['Scale 1\\n(Fine)', 'Scale 2\\n(Medium)', 'Scale 3\\n(Coarse)'])\n",
        "    plt.yticks(range(len(config_names)), [name.replace('_', '\\n') for name in config_names])\n",
        "    plt.title('Scale Usage by Configuration')\n",
        "\n",
        "    # Add text annotations\n",
        "    for i in range(len(config_names)):\n",
        "        for j in range(3):\n",
        "            text = '✓' if scale_matrix[i, j] == 1 else '✗'\n",
        "            color = 'white' if scale_matrix[i, j] == 1 else 'black'\n",
        "            plt.text(j, i, text, ha='center', va='center', color=color, fontsize=12, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(Config.ablation_dir, \"ablation_analysis.png\"), dpi=300, bbox_inches='tight')\n",
        "    plt.savefig(os.path.join(Config.ablation_dir, \"ablation_analysis.pdf\"), bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Generate detailed report\n",
        "    with open(os.path.join(Config.ablation_dir, \"detailed_analysis_report.txt\"), 'w') as f:\n",
        "        f.write(\"FLAVA MULTI-SCALE FEATURE ABLATION STUDY REPORT\\n\")\n",
        "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
        "\n",
        "        f.write(\"EXECUTIVE SUMMARY:\\n\")\n",
        "        f.write(f\"- Baseline (Full Multi-scale): {baseline_iou:.4f} IoU\\n\")\n",
        "        f.write(f\"- Best single-scale: {results['single_scale']['best_val_iou']:.4f} IoU\\n\")\n",
        "        f.write(f\"- Multi-scale advantage: {(baseline_iou - results['single_scale']['best_val_iou']):.4f} IoU\\n\\n\")\n",
        "\n",
        "        f.write(\"DETAILED RESULTS:\\n\")\n",
        "        f.write(\"-\" * 60 + \"\\n\")\n",
        "        for name, data in results.items():\n",
        "            f.write(f\"Configuration: {name}\\n\")\n",
        "            f.write(f\"Description: {data['description']}\\n\")\n",
        "            f.write(f\"Active Scales: {data['scales']}\\n\")\n",
        "            f.write(f\"Best IoU: {data['best_val_iou']:.4f}\\n\")\n",
        "            if name in reductions:\n",
        "                f.write(f\"IoU Reduction: {reductions[name]['absolute_reduction']:.4f} ({reductions[name]['percentage_reduction']:.1f}%)\\n\")\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "        f.write(\"SCALE CONTRIBUTION ANALYSIS:\\n\")\n",
        "        f.write(\"-\" * 60 + \"\\n\")\n",
        "        f.write(\"Scale 1 (Fine Details): Essential for boundary precision\\n\")\n",
        "        if 'without_scale1' in reductions:\n",
        "            f.write(f\"  - Removal impact: {reductions['without_scale1']['percentage_reduction']:.1f}% IoU reduction\\n\")\n",
        "\n",
        "        f.write(\"Scale 2 (Medium Features): Important for medium-sized defects\\n\")\n",
        "        if 'without_scale2' in reductions:\n",
        "            f.write(f\"  - Removal impact: {reductions['without_scale2']['percentage_reduction']:.1f}% IoU reduction\\n\")\n",
        "\n",
        "        f.write(\"Scale 3 (Global Context): Critical for large defect identification\\n\")\n",
        "        if 'without_scale3' in reductions:\n",
        "            f.write(f\"  - Removal impact: {reductions['without_scale3']['percentage_reduction']:.1f}% IoU reduction\\n\")\n",
        "\n",
        "    return results_df, reductions\n",
        "\n",
        "# ==== MAIN EXECUTION ====\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting FLAVA Multi-scale Ablation Study...\")\n",
        "    print(\"This will train 5 different model configurations to analyze scale contributions.\")\n",
        "\n",
        "    try:\n",
        "        # Run ablation study\n",
        "        results = run_ablation_study()\n",
        "\n",
        "        # Analyze results\n",
        "        results_df, reductions = analyze_ablation_results(results)\n",
        "\n",
        "        print(f\"\\n✅ Ablation study completed successfully!\")\n",
        "        print(f\"📊 Results saved to: {Config.ablation_dir}\")\n",
        "        print(f\"📈 Visualizations and detailed report generated\")\n",
        "\n",
        "        # Print final summary for paper\n",
        "        print(f\"\\n\" + \"=\"*80)\n",
        "        print(\"SUMMARY FOR PAPER - MULTI-SCALE FEATURE CONTRIBUTION\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        baseline_iou = results['full_multiscale']['best_val_iou']\n",
        "\n",
        "        print(f\"**Feature Scale Analysis:**\")\n",
        "        print(f\"* Scale 1 (Original): Primary contribution to fine boundary delineation\")\n",
        "        print(f\"* Scale 2 (Medium): Important for medium-sized defect detection\")\n",
        "        print(f\"* Scale 3 (Coarse): Critical for global context and large defect identification\")\n",
        "        print(f\"\")\n",
        "        print(f\"**Ablation Study Results:**\")\n",
        "        print(f\"Systematic removal of each scale demonstrates complementary contributions:\")\n",
        "\n",
        "        if 'without_scale1' in reductions:\n",
        "            red1 = reductions['without_scale1']['percentage_reduction']\n",
        "            print(f\"* Without Scale 1: {red1:.1f}% IoU reduction, poor boundary precision\")\n",
        "\n",
        "        if 'without_scale2' in reductions:\n",
        "            red2 = reductions['without_scale2']['percentage_reduction']\n",
        "            print(f\"* Without Scale 2: {red2:.1f}% IoU reduction, missed medium defects\")\n",
        "\n",
        "        if 'without_scale3' in reductions:\n",
        "            red3 = reductions['without_scale3']['percentage_reduction']\n",
        "            print(f\"* Without Scale 3: {red3:.1f}% IoU reduction, poor global context integration\")\n",
        "\n",
        "        print(f\"\\nBaseline Performance: {baseline_iou:.4f} IoU\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during ablation study: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FLAVA Defect Segmentation - Loss Function Ablation Study\n",
        "# Comprehensive analysis of different loss functions and their components\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Resize\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import FlavaModel, FlavaProcessor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ==== CONFIG ====\n",
        "class Config:\n",
        "\n",
        "    base_model_path = \"/content/drive/MyDrive/Colab Notebooks/YOLO/YOLO12Result/outputs_flava/flava_finetuned\"\n",
        "    data_path = \"/content/drive/MyDrive/Colab Notebooks/YOLO/YOLO12Result/Data12 class segmentation\"\n",
        "    save_path = \"/content/drive/MyDrive/Colab Notebooks/YOLO/YOLO12Result/loss_ablation_study\"\n",
        "    debug_dir = os.path.join(save_path, \"debug\")\n",
        "    plots_dir = os.path.join(save_path, \"plots\")\n",
        "    metrics_dir = os.path.join(save_path, \"metrics\")\n",
        "    loss_ablation_dir = os.path.join(save_path, \"loss_ablation_results\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    batch_size = 4\n",
        "    num_epochs = 6  # Reduced for ablation study\n",
        "    lr = 2e-5\n",
        "    patch_grid = 14\n",
        "    mask_size = (14, 14)\n",
        "    test_split = 0.2\n",
        "\n",
        "# Create necessary directories\n",
        "for directory in [Config.save_path, Config.debug_dir, Config.plots_dir, Config.metrics_dir, Config.loss_ablation_dir]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "print(f\"Using device: {Config.device}\")\n",
        "\n",
        "# ==== DATASET ====\n",
        "class MaskedDataset(Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.imgs, self.masks = [], []\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        self.mask_resize = Resize(Config.mask_size)\n",
        "\n",
        "        for cls in os.listdir(data_dir):\n",
        "            p = os.path.join(data_dir, cls)\n",
        "            if not os.path.isdir(p): continue\n",
        "            for f in os.listdir(p):\n",
        "                if f.endswith(\".json\"):\n",
        "                    img = os.path.join(p, f.replace(\".json\", \".jpg\"))\n",
        "                    jsn = os.path.join(p, f)\n",
        "                    if os.path.exists(img):\n",
        "                        self.imgs.append(img)\n",
        "                        self.masks.append(jsn)\n",
        "\n",
        "        print(f\"Found {len(self.imgs)} images with masks\")\n",
        "\n",
        "    def __len__(self): return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open(self.imgs[i]).convert(\"RGB\")\n",
        "        img_tensor = self.img_transform(img)\n",
        "\n",
        "        mask_arr = np.zeros((640, 640), dtype=np.uint8)\n",
        "        with open(self.masks[i]) as f:\n",
        "            data = json.load(f)\n",
        "            for ann in data.get('annotations', []):\n",
        "                x, y, w, h = map(int, ann['bbox'])\n",
        "                x2, y2 = min(x+w, 640), min(y+h, 640)\n",
        "                mask_arr[y:y2, x:x2] = 1\n",
        "        mask = self.mask_resize(Image.fromarray(mask_arr * 255))\n",
        "        mask_tensor = transforms.ToTensor()(mask).float().squeeze(0)\n",
        "\n",
        "        return img_tensor, mask_tensor, self.imgs[i]\n",
        "\n",
        "# ==== DIFFERENT LOSS FUNCTIONS ====\n",
        "\n",
        "class BCELoss(nn.Module):\n",
        "    \"\"\"Standard Binary Cross Entropy Loss\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.name = \"BCE\"\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        return F.binary_cross_entropy_with_logits(inputs, targets)\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Pure Dice Loss\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.name = \"Dice\"\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        inputs_sigmoid = torch.sigmoid(inputs)\n",
        "        intersection = (inputs_sigmoid * targets).sum((1,2))\n",
        "        union = (inputs_sigmoid + targets).sum((1,2))\n",
        "        dice_loss = 1 - (2. * intersection + 1e-6) / (union + 1e-6)\n",
        "        return dice_loss.mean()\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Pure Focal Loss\"\"\"\n",
        "    def __init__(self, alpha=0.25, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.name = f\"Focal_a{alpha}_g{gamma}\"\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        probs = torch.sigmoid(inputs)\n",
        "        pt = torch.where(targets == 1, probs, 1-probs)\n",
        "        focal_weight = self.alpha * (1-pt) ** self.gamma\n",
        "        focal_loss = focal_weight * bce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "    \"\"\"Combined BCE + Dice Loss\"\"\"\n",
        "    def __init__(self, bce_weight=0.5):\n",
        "        super().__init__()\n",
        "        self.bce_weight = bce_weight\n",
        "        self.bce = BCELoss()\n",
        "        self.dice = DiceLoss()\n",
        "        self.name = f\"BCE+Dice_w{bce_weight}\"\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        bce_loss = self.bce(inputs, targets)\n",
        "        dice_loss = self.dice(inputs, targets)\n",
        "        return self.bce_weight * bce_loss + (1 - self.bce_weight) * dice_loss\n",
        "\n",
        "class FocalDiceLoss(nn.Module):\n",
        "    \"\"\"Combined Focal + Dice Loss with configurable parameters\"\"\"\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, beta=0.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.beta = beta\n",
        "        self.name = f\"FocalDice_a{alpha}_g{gamma}_b{beta}\"\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # Focal component\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        probs = torch.sigmoid(inputs)\n",
        "        pt = torch.where(targets == 1, probs, 1-probs)\n",
        "        focal_weight = self.alpha * (1-pt) ** self.gamma\n",
        "        focal_loss = focal_weight * bce_loss\n",
        "\n",
        "        # Dice component\n",
        "        inputs_sigmoid = torch.sigmoid(inputs)\n",
        "        intersection = (inputs_sigmoid * targets).sum((1,2))\n",
        "        union = (inputs_sigmoid + targets).sum((1,2))\n",
        "        dice_loss = 1 - (2. * intersection + 1e-6) / (union + 1e-6)\n",
        "\n",
        "        # Combine\n",
        "        combined_loss = self.beta * focal_loss.mean() + (1-self.beta) * dice_loss.mean()\n",
        "        return combined_loss\n",
        "\n",
        "class TverskyLoss(nn.Module):\n",
        "    \"\"\"Tversky Loss - generalization of Dice loss\"\"\"\n",
        "    def __init__(self, alpha=0.3, beta=0.7):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # False positive penalty\n",
        "        self.beta = beta    # False negative penalty\n",
        "        self.name = f\"Tversky_a{alpha}_b{beta}\"\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        inputs_sigmoid = torch.sigmoid(inputs)\n",
        "\n",
        "        # True positives, false positives, false negatives\n",
        "        tp = (inputs_sigmoid * targets).sum((1,2))\n",
        "        fp = (inputs_sigmoid * (1-targets)).sum((1,2))\n",
        "        fn = ((1-inputs_sigmoid) * targets).sum((1,2))\n",
        "\n",
        "        tversky_coeff = tp / (tp + self.alpha * fp + self.beta * fn + 1e-6)\n",
        "        tversky_loss = 1 - tversky_coeff\n",
        "        return tversky_loss.mean()\n",
        "\n",
        "class WeightedBCELoss(nn.Module):\n",
        "    \"\"\"Weighted BCE for class imbalance\"\"\"\n",
        "    def __init__(self, pos_weight=2.0):\n",
        "        super().__init__()\n",
        "        self.pos_weight = pos_weight\n",
        "        self.name = f\"WeightedBCE_w{pos_weight}\"\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        return F.binary_cross_entropy_with_logits(\n",
        "            inputs, targets,\n",
        "            pos_weight=torch.tensor(self.pos_weight).to(inputs.device)\n",
        "        )\n",
        "\n",
        "# ==== LOSS CONFIGURATIONS FOR ABLATION ====\n",
        "def get_loss_configurations():\n",
        "    \"\"\"Define all loss function configurations to test\"\"\"\n",
        "\n",
        "    loss_configs = [\n",
        "        # Basic losses\n",
        "        {'name': 'bce', 'loss_fn': BCELoss(), 'description': 'Standard Binary Cross Entropy'},\n",
        "        {'name': 'dice', 'loss_fn': DiceLoss(), 'description': 'Pure Dice Loss'},\n",
        "        {'name': 'weighted_bce', 'loss_fn': WeightedBCELoss(pos_weight=2.0), 'description': 'Weighted BCE (pos_weight=2.0)'},\n",
        "\n",
        "        # Focal loss variants\n",
        "        {'name': 'focal_standard', 'loss_fn': FocalLoss(alpha=0.25, gamma=2.0), 'description': 'Standard Focal Loss'},\n",
        "        {'name': 'focal_high_gamma', 'loss_fn': FocalLoss(alpha=0.25, gamma=5.0), 'description': 'Focal Loss (high focus)'},\n",
        "        {'name': 'focal_low_gamma', 'loss_fn': FocalLoss(alpha=0.25, gamma=1.0), 'description': 'Focal Loss (low focus)'},\n",
        "\n",
        "        # Combined losses\n",
        "        {'name': 'bce_dice_balanced', 'loss_fn': BCEDiceLoss(bce_weight=0.5), 'description': 'BCE + Dice (balanced)'},\n",
        "        {'name': 'bce_dice_bce_heavy', 'loss_fn': BCEDiceLoss(bce_weight=0.7), 'description': 'BCE + Dice (BCE heavy)'},\n",
        "        {'name': 'bce_dice_dice_heavy', 'loss_fn': BCEDiceLoss(bce_weight=0.3), 'description': 'BCE + Dice (Dice heavy)'},\n",
        "\n",
        "        # FocalDice variants\n",
        "        {'name': 'focaldice_standard', 'loss_fn': FocalDiceLoss(alpha=0.25, gamma=2.0, beta=0.5), 'description': 'Standard FocalDice'},\n",
        "        {'name': 'focaldice_focal_heavy', 'loss_fn': FocalDiceLoss(alpha=0.25, gamma=2.0, beta=0.7), 'description': 'FocalDice (Focal heavy)'},\n",
        "        {'name': 'focaldice_dice_heavy', 'loss_fn': FocalDiceLoss(alpha=0.25, gamma=2.0, beta=0.3), 'description': 'FocalDice (Dice heavy)'},\n",
        "\n",
        "        # Tversky variants\n",
        "        {'name': 'tversky_balanced', 'loss_fn': TverskyLoss(alpha=0.3, beta=0.7), 'description': 'Tversky (recall focused)'},\n",
        "        {'name': 'tversky_precision', 'loss_fn': TverskyLoss(alpha=0.7, beta=0.3), 'description': 'Tversky (precision focused)'},\n",
        "    ]\n",
        "\n",
        "    return loss_configs\n",
        "\n",
        "# ==== SEGMENTATION MODEL ====\n",
        "class SimpleFLAVASegmenter(nn.Module):\n",
        "    \"\"\"Simplified FLAVA segmenter for loss ablation\"\"\"\n",
        "    def __init__(self, base_model_path):\n",
        "        super().__init__()\n",
        "        self.model = FlavaModel.from_pretrained(base_model_path)\n",
        "\n",
        "        # Simple single-scale approach for consistent comparison\n",
        "        self.projection = nn.Linear(self.model.config.hidden_size, 256)\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, pixel_inputs):\n",
        "        outputs = self.model(pixel_values=pixel_inputs)\n",
        "        patches = outputs.image_embeddings[:, 1:, :]  # Skip CLS token\n",
        "\n",
        "        b, n, c = patches.shape\n",
        "        projected = self.projection(patches)\n",
        "        spatial = projected.reshape(b, Config.patch_grid, Config.patch_grid, -1).permute(0, 3, 1, 2)\n",
        "        seg_logits = self.head(spatial)\n",
        "        return seg_logits\n",
        "\n",
        "# ==== EVALUATION FUNCTIONS ====\n",
        "def calculate_metrics(preds, masks):\n",
        "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
        "    intersection = (preds * masks).sum((1,2))\n",
        "    union = ((preds + masks) >= 1).float().sum((1,2))\n",
        "    batch_iou = (intersection / (union + 1e-6))\n",
        "\n",
        "    dice = (2 * intersection) / (preds.sum((1,2)) + masks.sum((1,2)) + 1e-6)\n",
        "\n",
        "    tp = (preds * masks).sum((1,2))\n",
        "    fp = (preds * (1-masks)).sum((1,2))\n",
        "    fn = ((1-preds) * masks).sum((1,2))\n",
        "    tn = ((1-preds) * (1-masks)).sum((1,2))\n",
        "\n",
        "    precision = tp / (tp + fp + 1e-6)\n",
        "    recall = tp / (tp + fn + 1e-6)\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-6)\n",
        "\n",
        "    metrics = {\n",
        "        'iou': batch_iou.mean().item(),\n",
        "        'dice': dice.mean().item(),\n",
        "        'precision': precision.mean().item(),\n",
        "        'recall': recall.mean().item(),\n",
        "        'f1': f1.mean().item(),\n",
        "        'accuracy': accuracy.mean().item()\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def evaluate_model(model, dataloader, processor):\n",
        "    \"\"\"Evaluate model on a dataset\"\"\"\n",
        "    model.eval()\n",
        "    all_metrics = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks, _ in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            imgs, masks = imgs.to(Config.device), masks.to(Config.device)\n",
        "            pixel_inputs = processor(images=imgs, return_tensors=\"pt\")[\"pixel_values\"].to(Config.device)\n",
        "\n",
        "            logits = model(pixel_inputs).squeeze(1)\n",
        "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
        "\n",
        "            batch_metrics = calculate_metrics(preds, masks)\n",
        "            all_metrics.append(batch_metrics)\n",
        "\n",
        "    results = {}\n",
        "    for metric in all_metrics[0].keys():\n",
        "        results[metric] = np.mean([m[metric] for m in all_metrics])\n",
        "\n",
        "    return results\n",
        "\n",
        "# ==== TRAINING FUNCTION ====\n",
        "def train_with_loss(loss_config, train_loader, val_loader, processor):\n",
        "    \"\"\"Train model with specific loss function\"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Training with {loss_config['name']}: {loss_config['description']}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    model = SimpleFLAVASegmenter(Config.base_model_path).to(Config.device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=Config.lr)\n",
        "    loss_fn = loss_config['loss_fn']\n",
        "\n",
        "    best_val_iou = 0\n",
        "    best_val_dice = 0\n",
        "    best_val_f1 = 0\n",
        "\n",
        "    metrics_history = {\n",
        "        'train_loss': [], 'val_iou': [], 'val_dice': [], 'val_f1': [], 'val_precision': [], 'val_recall': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(Config.num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "\n",
        "        for imgs, masks, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config.num_epochs}\"):\n",
        "            imgs, masks = imgs.to(Config.device), masks.to(Config.device)\n",
        "            pixel_inputs = processor(images=imgs, return_tensors=\"pt\")[\"pixel_values\"].to(Config.device)\n",
        "\n",
        "            logits = model(pixel_inputs).squeeze(1)\n",
        "            loss = loss_fn(logits, masks)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        # Validation phase\n",
        "        val_metrics = evaluate_model(model, val_loader, processor)\n",
        "\n",
        "        # Update history\n",
        "        metrics_history['train_loss'].append(np.mean(train_losses))\n",
        "        for metric in val_metrics:\n",
        "            if f'val_{metric}' in metrics_history:\n",
        "                metrics_history[f'val_{metric}'].append(val_metrics[metric])\n",
        "\n",
        "        # Save best metrics\n",
        "        if val_metrics['iou'] > best_val_iou:\n",
        "            best_val_iou = val_metrics['iou']\n",
        "            best_val_dice = val_metrics['dice']\n",
        "            best_val_f1 = val_metrics['f1']\n",
        "            torch.save(model.state_dict(),\n",
        "                      os.path.join(Config.save_path, f\"best_model_{loss_config['name']}.pth\"))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Loss: {np.mean(train_losses):.4f}, \"\n",
        "              f\"IoU: {val_metrics['iou']:.4f}, Dice: {val_metrics['dice']:.4f}, F1: {val_metrics['f1']:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'best_iou': best_val_iou,\n",
        "        'best_dice': best_val_dice,\n",
        "        'best_f1': best_val_f1,\n",
        "        'final_metrics': val_metrics,\n",
        "        'history': metrics_history\n",
        "    }\n",
        "\n",
        "# ==== LOSS ABLATION STUDY ====\n",
        "def run_loss_ablation_study():\n",
        "    \"\"\"Run complete loss function ablation study\"\"\"\n",
        "\n",
        "    # Load dataset\n",
        "    full_dataset = MaskedDataset(Config.data_path)\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        range(len(full_dataset)), test_size=Config.test_split, random_state=42\n",
        "    )\n",
        "\n",
        "    train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
        "    val_dataset = torch.utils.data.Subset(full_dataset, val_indices)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=Config.batch_size, shuffle=False)\n",
        "\n",
        "    processor = FlavaProcessor.from_pretrained(Config.base_model_path)\n",
        "    processor.image_processor.do_rescale = False\n",
        "\n",
        "    print(f\"Dataset: {len(train_dataset)} train, {len(val_dataset)} val samples\")\n",
        "\n",
        "    # Get loss configurations\n",
        "    loss_configs = get_loss_configurations()\n",
        "\n",
        "    # Results storage\n",
        "    ablation_results = {}\n",
        "\n",
        "    # Train with each loss function\n",
        "    for config in loss_configs:\n",
        "        try:\n",
        "            results = train_with_loss(config, train_loader, val_loader, processor)\n",
        "\n",
        "            ablation_results[config['name']] = {\n",
        "                'description': config['description'],\n",
        "                'loss_function': config['loss_fn'].name if hasattr(config['loss_fn'], 'name') else config['name'],\n",
        "                'best_iou': results['best_iou'],\n",
        "                'best_dice': results['best_dice'],\n",
        "                'best_f1': results['best_f1'],\n",
        "                'final_precision': results['final_metrics']['precision'],\n",
        "                'final_recall': results['final_metrics']['recall'],\n",
        "                'history': results['history']\n",
        "            }\n",
        "\n",
        "            print(f\"✅ {config['name']}: IoU={results['best_iou']:.4f}, Dice={results['best_dice']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error with {config['name']}: {e}\")\n",
        "            continue\n",
        "\n",
        "    return ablation_results\n",
        "\n",
        "# ==== ANALYSIS AND VISUALIZATION ====\n",
        "def analyze_loss_ablation_results(results):\n",
        "    \"\"\"Analyze and visualize loss ablation study results\"\"\"\n",
        "\n",
        "    # Extract metrics\n",
        "    loss_names = []\n",
        "    descriptions = []\n",
        "    iou_scores = []\n",
        "    dice_scores = []\n",
        "    f1_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "\n",
        "    for name, data in results.items():\n",
        "        loss_names.append(name)\n",
        "        descriptions.append(data['description'])\n",
        "        iou_scores.append(data['best_iou'])\n",
        "        dice_scores.append(data['best_dice'])\n",
        "        f1_scores.append(data['best_f1'])\n",
        "        precision_scores.append(data['final_precision'])\n",
        "        recall_scores.append(data['final_recall'])\n",
        "\n",
        "    # Create results dataframe\n",
        "    results_df = pd.DataFrame({\n",
        "        'Loss_Function': loss_names,\n",
        "        'Description': descriptions,\n",
        "        'IoU': iou_scores,\n",
        "        'Dice': dice_scores,\n",
        "        'F1': f1_scores,\n",
        "        'Precision': precision_scores,\n",
        "        'Recall': recall_scores\n",
        "    })\n",
        "\n",
        "    # Sort by IoU for better visualization\n",
        "    results_df = results_df.sort_values('IoU', ascending=False)\n",
        "\n",
        "    # Save results\n",
        "    results_df.to_csv(os.path.join(Config.loss_ablation_dir, \"loss_ablation_results.csv\"), index=False)\n",
        "\n",
        "    # Find best performing loss\n",
        "    best_loss = results_df.iloc[0]\n",
        "    worst_loss = results_df.iloc[-1]\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"LOSS FUNCTION ABLATION STUDY RESULTS\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"🏆 Best Loss Function: {best_loss['Loss_Function']}\")\n",
        "    print(f\"   Description: {best_loss['Description']}\")\n",
        "    print(f\"   IoU: {best_loss['IoU']:.4f}, Dice: {best_loss['Dice']:.4f}, F1: {best_loss['F1']:.4f}\")\n",
        "    print(f\"\\n📉 Worst Loss Function: {worst_loss['Loss_Function']}\")\n",
        "    print(f\"   Description: {worst_loss['Description']}\")\n",
        "    print(f\"   IoU: {worst_loss['IoU']:.4f}, Dice: {worst_loss['Dice']:.4f}, F1: {worst_loss['F1']:.4f}\")\n",
        "    print(f\"\\n📊 Performance Gap: {(best_loss['IoU'] - worst_loss['IoU']):.4f} IoU difference\")\n",
        "\n",
        "    # Create comprehensive visualization\n",
        "    plt.figure(figsize=(20, 15))\n",
        "\n",
        "    # 1. IoU comparison\n",
        "    plt.subplot(3, 3, 1)\n",
        "    bars = plt.bar(range(len(loss_names)), results_df['IoU'],\n",
        "                   color=['gold' if i == 0 else 'steelblue' for i in range(len(loss_names))])\n",
        "    plt.xticks(range(len(loss_names)), results_df['Loss_Function'], rotation=45, ha='right')\n",
        "    plt.ylabel('IoU Score')\n",
        "    plt.title('IoU Performance by Loss Function')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add value labels\n",
        "    for bar, score in zip(bars, results_df['IoU']):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002,\n",
        "                f'{score:.3f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "    # 2. Dice comparison\n",
        "    plt.subplot(3, 3, 2)\n",
        "    plt.bar(range(len(loss_names)), results_df['Dice'], color='lightcoral')\n",
        "    plt.xticks(range(len(loss_names)), results_df['Loss_Function'], rotation=45, ha='right')\n",
        "    plt.ylabel('Dice Score')\n",
        "    plt.title('Dice Performance by Loss Function')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 3. F1 comparison\n",
        "    plt.subplot(3, 3, 3)\n",
        "    plt.bar(range(len(loss_names)), results_df['F1'], color='lightgreen')\n",
        "    plt.xticks(range(len(loss_names)), results_df['Loss_Function'], rotation=45, ha='right')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.title('F1 Performance by Loss Function')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 4. Precision vs Recall scatter\n",
        "    plt.subplot(3, 3, 4)\n",
        "    scatter = plt.scatter(results_df['Precision'], results_df['Recall'],\n",
        "                         c=results_df['IoU'], cmap='viridis', s=100, alpha=0.7)\n",
        "    plt.xlabel('Precision')\n",
        "    plt.ylabel('Recall')\n",
        "    plt.title('Precision vs Recall (colored by IoU)')\n",
        "    plt.colorbar(scatter, label='IoU Score')\n",
        "\n",
        "    # Add labels for each point\n",
        "    for i, row in results_df.iterrows():\n",
        "        plt.annotate(row['Loss_Function'], (row['Precision'], row['Recall']),\n",
        "                    xytext=(5, 5), textcoords='offset points', fontsize=6)\n",
        "\n",
        "    # 5. Radar chart for top 5 loss functions\n",
        "    plt.subplot(3, 3, 5, projection='polar')\n",
        "    top_5 = results_df.head(5)\n",
        "\n",
        "    categories = ['IoU', 'Dice', 'F1', 'Precision', 'Recall']\n",
        "    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
        "    angles += angles[:1]  # Complete the circle\n",
        "\n",
        "    colors = plt.cm.Set1(np.linspace(0, 1, len(top_5)))\n",
        "\n",
        "    for i, (_, row) in enumerate(top_5.iterrows()):\n",
        "        values = [row['IoU'], row['Dice'], row['F1'], row['Precision'], row['Recall']]\n",
        "        values += values[:1]  # Complete the circle\n",
        "\n",
        "        plt.plot(angles, values, 'o-', linewidth=2, label=row['Loss_Function'], color=colors[i])\n",
        "        plt.fill(angles, values, alpha=0.1, color=colors[i])\n",
        "\n",
        "    plt.xticks(angles[:-1], categories)\n",
        "    plt.title('Top 5 Loss Functions - Multi-metric Comparison')\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
        "\n",
        "    # 6. Loss function category analysis\n",
        "    plt.subplot(3, 3, 6)\n",
        "\n",
        "    # Categorize loss functions\n",
        "    categories_data = {\n",
        "        'Basic': ['bce', 'dice', 'weighted_bce'],\n",
        "        'Focal': ['focal_standard', 'focal_high_gamma', 'focal_low_gamma'],\n",
        "        'Combined': ['bce_dice_balanced', 'bce_dice_bce_heavy', 'bce_dice_dice_heavy',\n",
        "                    'focaldice_standard', 'focaldice_focal_heavy', 'focaldice_dice_heavy'],\n",
        "        'Advanced': ['tversky_balanced', 'tversky_precision']\n",
        "    }\n",
        "\n",
        "    category_means = {}\n",
        "    for category, loss_list in categories_data.items():\n",
        "        category_ious = [results_df[results_df['Loss_Function'] == loss]['IoU'].values[0]\n",
        "                        for loss in loss_list if loss in results_df['Loss_Function'].values]\n",
        "        if category_ious:\n",
        "            category_means[category] = np.mean(category_ious)\n",
        "\n",
        "    plt.bar(category_means.keys(), category_means.values(), color='skyblue')\n",
        "    plt.ylabel('Mean IoU')\n",
        "    plt.title('Performance by Loss Function Category')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 7. Training convergence comparison (top 3)\n",
        "    plt.subplot(3, 3, 7)\n",
        "    top_3 = results_df.head(3)\n",
        "\n",
        "    for _, row in top_3.iterrows():\n",
        "        loss_name = row['Loss_Function']\n",
        "        if loss_name in results and 'history' in results[loss_name]:\n",
        "            history = results[loss_name]['history']\n",
        "            if 'val_iou' in history and history['val_iou']:\n",
        "                epochs = range(1, len(history['val_iou']) + 1)\n",
        "                plt.plot(epochs, history['val_iou'], label=loss_name, marker='o')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Validation IoU')\n",
        "    plt.title('Training Convergence - Top 3 Loss Functions')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 8. Statistical analysis\n",
        "    plt.subplot(3, 3, 8)\n",
        "    metrics_for_box = ['IoU', 'Dice', 'F1', 'Precision', 'Recall']\n",
        "    box_data = [results_df[metric].values for metric in metrics_for_box]\n",
        "\n",
        "    box_plot = plt.boxplot(box_data, labels=metrics_for_box, patch_artist=True)\n",
        "    colors = ['lightblue', 'lightgreen', 'lightyellow', 'lightcoral', 'lightpink']\n",
        "    for patch, color in zip(box_plot['boxes'], colors):\n",
        "        patch.set_facecolor(color)\n",
        "\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Distribution of Metrics Across All Loss Functions')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 9. Improvement over baseline\n",
        "    plt.subplot(3, 3, 9)\n",
        "    baseline_iou = results_df[results_df['Loss_Function'] == 'bce']['IoU'].values[0]\n",
        "    improvements = [(score - baseline_iou) * 100 for score in results_df['IoU']]\n",
        "\n",
        "    colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
        "    bars = plt.bar(range(len(loss_names)), improvements, color=colors, alpha=0.7)\n",
        "    plt.xticks(range(len(loss_names)), results_df['Loss_Function'], rotation=45, ha='right')\n",
        "    plt.ylabel('IoU Improvement over BCE (%)')\n",
        "    plt.title('Relative Performance vs Baseline (BCE)')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(Config.loss_ablation_dir, \"loss_ablation_analysis.png\"), dpi=300, bbox_inches='tight')\n",
        "    plt.savefig(os.path.join(Config.loss_ablation_dir, \"loss_ablation_analysis.pdf\"), bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Generate detailed report\n",
        "    with open(os.path.join(Config.loss_ablation_dir, \"loss_ablation_report.txt\"), 'w') as f:\n",
        "        f.write(\"FLAVA DEFECT SEGMENTATION - LOSS FUNCTION ABLATION STUDY\\n\")\n",
        "        f.write(\"=\" * 70 + \"\\n\\n\")\n",
        "\n",
        "        f.write(\"EXECUTIVE SUMMARY:\\n\")\n",
        "        f.write(f\"- Best Loss Function: {best_loss['Loss_Function']} (IoU: {best_loss['IoU']:.4f})\\n\")\n",
        "        f.write(f\"- Worst Loss Function: {worst_loss['Loss_Function']} (IoU: {worst_loss['IoU']:.4f})\\n\")\n",
        "        f.write(f\"- Performance Range: {(best_loss['IoU'] - worst_loss['IoU']):.4f} IoU difference\\n\\n\")\n",
        "\n",
        "        f.write(\"TOP 5 LOSS FUNCTIONS:\\n\")\n",
        "        f.write(\"-\" * 70 + \"\\n\")\n",
        "        for i, (_, row) in enumerate(results_df.head(5).iterrows()):\n",
        "            f.write(f\"{i+1}. {row['Loss_Function']}\\n\")\n",
        "            f.write(f\"   Description: {row['Description']}\\n\")\n",
        "            f.write(f\"   IoU: {row['IoU']:.4f}, Dice: {row['Dice']:.4f}, F1: {row['F1']:.4f}\\n\")\n",
        "            f.write(f\"   Precision: {row['Precision']:.4f}, Recall: {row['Recall']:.4f}\\n\\n\")\n",
        "\n",
        "        f.write(\"CATEGORY ANALYSIS:\\n\")\n",
        "        f.write(\"-\" * 70 + \"\\n\")\n",
        "        for category, mean_iou in category_means.items():\n",
        "            f.write(f\"{category} Loss Functions: Mean IoU = {mean_iou:.4f}\\n\")\n",
        "\n",
        "        f.write(f\"\\nRECOMMENDATIONS:\\n\")\n",
        "        f.write(\"-\" * 70 + \"\\n\")\n",
        "        f.write(f\"1. Use {best_loss['Loss_Function']} for optimal IoU performance\\n\")\n",
        "        f.write(f\"2. Consider precision-recall trade-offs based on application needs\\n\")\n",
        "        f.write(f\"3. FocalDice variants show good balance between metrics\\n\")\n",
        "        f.write(f\"4. Avoid basic BCE for defect segmentation tasks\\n\")\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# ==== MAIN EXECUTION ====\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting FLAVA Loss Function Ablation Study...\")\n",
        "    print(\"This will test 14 different loss function configurations.\")\n",
        "\n",
        "    try:\n",
        "        # Run loss ablation study\n",
        "        results = run_loss_ablation_study()\n",
        "\n",
        "        # Analyze results\n",
        "        results_df = analyze_loss_ablation_results(results)\n",
        "\n",
        "        print(f\"\\n✅ Loss function ablation study completed successfully!\")\n",
        "        print(f\"📊 Results saved to: {Config.loss_ablation_dir}\")\n",
        "        print(f\"📈 Comprehensive analysis and visualizations generated\")\n",
        "\n",
        "        # Print summary for paper\n",
        "        print(f\"\\n\" + \"=\"*80)\n",
        "        print(\"SUMMARY FOR PAPER - LOSS FUNCTION ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        best_loss = results_df.iloc[0]\n",
        "        baseline_bce = results_df[results_df['Loss_Function'] == 'bce']\n",
        "\n",
        "        if not baseline_bce.empty:\n",
        "            improvement = ((best_loss['IoU'] - baseline_bce['IoU'].values[0]) / baseline_bce['IoU'].values[0]) * 100\n",
        "            print(f\"**Optimal Loss Function:** {best_loss['Loss_Function']}\")\n",
        "            print(f\"- Performance: IoU={best_loss['IoU']:.4f}, Dice={best_loss['Dice']:.4f}\")\n",
        "            print(f\"- Improvement over BCE: +{improvement:.1f}% IoU\")\n",
        "            print(f\"- Configuration: {best_loss['Description']}\")\n",
        "\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during loss ablation study: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLPxxqWmyLAX",
        "outputId": "522df318-6622-4b45-8aaf-bc20f1218ec8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting FLAVA Loss Function Ablation Study...\n",
            "This will test 14 different loss function configurations.\n",
            "Found 522 images with masks\n",
            "Dataset: 417 train, 105 val samples\n",
            "\n",
            "======================================================================\n",
            "Training with bce: Standard Binary Cross Entropy\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:25<00:00,  4.15it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  7.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.4538, IoU: 0.5819, Dice: 0.5998, F1: 0.5998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:25<00:00,  4.05it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.3483, IoU: 0.5906, Dice: 0.6603, F1: 0.6603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:25<00:00,  4.18it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.2885, IoU: 0.6373, Dice: 0.6478, F1: 0.6478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:25<00:00,  4.18it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.2574, IoU: 0.6509, Dice: 0.6410, F1: 0.6410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.23it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  7.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.2505, IoU: 0.6752, Dice: 0.6151, F1: 0.6151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:25<00:00,  4.15it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.2237, IoU: 0.6415, Dice: 0.6102, F1: 0.6102\n",
            "✅ bce: IoU=0.6752, Dice=0.6151\n",
            "\n",
            "======================================================================\n",
            "Training with dice: Pure Dice Loss\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:25<00:00,  4.18it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.5869, IoU: 0.5329, Dice: 0.5986, F1: 0.5986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:24<00:00,  4.24it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.5220, IoU: 0.5057, Dice: 0.5944, F1: 0.5944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:24<00:00,  4.24it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.4971, IoU: 0.5615, Dice: 0.6301, F1: 0.6301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:24<00:00,  4.27it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.4837, IoU: 0.5699, Dice: 0.6528, F1: 0.6528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.29it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.4684, IoU: 0.5455, Dice: 0.6281, F1: 0.6281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.28it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.4586, IoU: 0.5578, Dice: 0.6507, F1: 0.6507\n",
            "✅ dice: IoU=0.5699, Dice=0.6528\n",
            "\n",
            "======================================================================\n",
            "Training with weighted_bce: Weighted BCE (pos_weight=2.0)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.37it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.5660, IoU: 0.6326, Dice: 0.6551, F1: 0.6551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:24<00:00,  4.32it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.4296, IoU: 0.5828, Dice: 0.6823, F1: 0.6823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:24<00:00,  4.32it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.3683, IoU: 0.5596, Dice: 0.6672, F1: 0.6672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:24<00:00,  4.37it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.3250, IoU: 0.5871, Dice: 0.6800, F1: 0.6800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.36it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.3011, IoU: 0.5054, Dice: 0.5789, F1: 0.5789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.36it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.3125, IoU: 0.6134, Dice: 0.6663, F1: 0.6663\n",
            "✅ weighted_bce: IoU=0.6326, Dice=0.6551\n",
            "\n",
            "======================================================================\n",
            "Training with focal_standard: Standard Focal Loss\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.35it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.0269, IoU: 0.6029, Dice: 0.5372, F1: 0.5372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:24<00:00,  4.30it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.0177, IoU: 0.6073, Dice: 0.5346, F1: 0.5346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:24<00:00,  4.27it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.0139, IoU: 0.4168, Dice: 0.3300, F1: 0.3300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:24<00:00,  4.29it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.0110, IoU: 0.5221, Dice: 0.4289, F1: 0.4289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.24it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.0096, IoU: 0.5106, Dice: 0.4303, F1: 0.4303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.22it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.0078, IoU: 0.4973, Dice: 0.3911, F1: 0.3911\n",
            "✅ focal_standard: IoU=0.6073, Dice=0.5346\n",
            "\n",
            "======================================================================\n",
            "Training with focal_high_gamma: Focal Loss (high focus)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.23it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.0039, IoU: 0.4334, Dice: 0.4097, F1: 0.4097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:25<00:00,  4.15it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.0022, IoU: 0.3936, Dice: 0.3169, F1: 0.3169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:24<00:00,  4.20it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.0015, IoU: 0.3828, Dice: 0.2959, F1: 0.2959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:24<00:00,  4.22it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.0012, IoU: 0.3681, Dice: 0.2912, F1: 0.2912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.22it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.0009, IoU: 0.4231, Dice: 0.3271, F1: 0.3271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.20it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.0007, IoU: 0.4537, Dice: 0.3426, F1: 0.3426\n",
            "✅ focal_high_gamma: IoU=0.4537, Dice=0.3426\n",
            "\n",
            "======================================================================\n",
            "Training with focal_low_gamma: Focal Loss (low focus)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.22it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.0789, IoU: 0.5146, Dice: 0.4456, F1: 0.4456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:25<00:00,  4.18it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  7.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.0500, IoU: 0.6169, Dice: 0.5372, F1: 0.5372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:25<00:00,  4.19it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.0410, IoU: 0.5877, Dice: 0.5131, F1: 0.5131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:25<00:00,  4.17it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.0344, IoU: 0.6245, Dice: 0.5352, F1: 0.5352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.23it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.0309, IoU: 0.6838, Dice: 0.6151, F1: 0.6151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:25<00:00,  4.16it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.0305, IoU: 0.6724, Dice: 0.5345, F1: 0.5345\n",
            "✅ focal_low_gamma: IoU=0.6838, Dice=0.6151\n",
            "\n",
            "======================================================================\n",
            "Training with bce_dice_balanced: BCE + Dice (balanced)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.20it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.5853, IoU: 0.5573, Dice: 0.6558, F1: 0.6558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:24<00:00,  4.24it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.4769, IoU: 0.5459, Dice: 0.6490, F1: 0.6490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:24<00:00,  4.31it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.4367, IoU: 0.6340, Dice: 0.7110, F1: 0.7110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:24<00:00,  4.25it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.4096, IoU: 0.6572, Dice: 0.7173, F1: 0.7173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.24it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.3949, IoU: 0.6820, Dice: 0.7275, F1: 0.7275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.30it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.3816, IoU: 0.6855, Dice: 0.7271, F1: 0.7271\n",
            "✅ bce_dice_balanced: IoU=0.6855, Dice=0.7271\n",
            "\n",
            "======================================================================\n",
            "Training with bce_dice_bce_heavy: BCE + Dice (BCE heavy)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.25it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.5834, IoU: 0.5747, Dice: 0.6275, F1: 0.6275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:24<00:00,  4.22it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.4646, IoU: 0.6235, Dice: 0.6472, F1: 0.6472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:24<00:00,  4.23it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.4304, IoU: 0.4909, Dice: 0.5689, F1: 0.5689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:24<00:00,  4.24it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.4175, IoU: 0.6423, Dice: 0.6787, F1: 0.6787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.26it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.3837, IoU: 0.6401, Dice: 0.6604, F1: 0.6604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.22it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.3668, IoU: 0.6741, Dice: 0.6889, F1: 0.6889\n",
            "✅ bce_dice_bce_heavy: IoU=0.6741, Dice=0.6889\n",
            "\n",
            "======================================================================\n",
            "Training with bce_dice_dice_heavy: BCE + Dice (Dice heavy)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.30it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.5713, IoU: 0.5721, Dice: 0.6716, F1: 0.6716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:24<00:00,  4.24it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.4921, IoU: 0.5854, Dice: 0.6798, F1: 0.6798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:24<00:00,  4.31it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.4501, IoU: 0.6312, Dice: 0.7021, F1: 0.7021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:24<00:00,  4.27it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.4359, IoU: 0.6351, Dice: 0.7085, F1: 0.7085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.29it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.4182, IoU: 0.6585, Dice: 0.6968, F1: 0.6968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.36it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.4108, IoU: 0.6651, Dice: 0.7159, F1: 0.7159\n",
            "✅ bce_dice_dice_heavy: IoU=0.6651, Dice=0.7159\n",
            "\n",
            "======================================================================\n",
            "Training with focaldice_standard: Standard FocalDice\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.37it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.3249, IoU: 0.4190, Dice: 0.5161, F1: 0.5161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:23<00:00,  4.38it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.2853, IoU: 0.5348, Dice: 0.6179, F1: 0.6179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:24<00:00,  4.33it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00, 10.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.2667, IoU: 0.5759, Dice: 0.6652, F1: 0.6652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:24<00:00,  4.35it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.2580, IoU: 0.5756, Dice: 0.6360, F1: 0.6360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.37it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.2556, IoU: 0.6045, Dice: 0.6700, F1: 0.6700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.32it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.2514, IoU: 0.5698, Dice: 0.6407, F1: 0.6407\n",
            "✅ focaldice_standard: IoU=0.6045, Dice=0.6700\n",
            "\n",
            "======================================================================\n",
            "Training with focaldice_focal_heavy: FocalDice (Focal heavy)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.27it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.2173, IoU: 0.5151, Dice: 0.6171, F1: 0.6171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:24<00:00,  4.30it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.1945, IoU: 0.6130, Dice: 0.6799, F1: 0.6799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:24<00:00,  4.30it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.1853, IoU: 0.6026, Dice: 0.6783, F1: 0.6783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:24<00:00,  4.28it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.1756, IoU: 0.6127, Dice: 0.6911, F1: 0.6911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.35it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.1728, IoU: 0.6064, Dice: 0.6934, F1: 0.6934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.32it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.1690, IoU: 0.6130, Dice: 0.6878, F1: 0.6878\n",
            "✅ focaldice_focal_heavy: IoU=0.6130, Dice=0.6878\n",
            "\n",
            "======================================================================\n",
            "Training with focaldice_dice_heavy: FocalDice (Dice heavy)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.30it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.4200, IoU: 0.5446, Dice: 0.6317, F1: 0.6317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:24<00:00,  4.23it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.3615, IoU: 0.5558, Dice: 0.6460, F1: 0.6460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:23<00:00,  4.39it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.3353, IoU: 0.6032, Dice: 0.6767, F1: 0.6767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:26<00:00,  3.91it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.3193, IoU: 0.6346, Dice: 0.6995, F1: 0.6995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.25it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.3146, IoU: 0.6297, Dice: 0.6831, F1: 0.6831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.37it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.3070, IoU: 0.5767, Dice: 0.6610, F1: 0.6610\n",
            "✅ focaldice_dice_heavy: IoU=0.6346, Dice=0.6995\n",
            "\n",
            "======================================================================\n",
            "Training with tversky_balanced: Tversky (recall focused)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.36it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.5422, IoU: 0.4433, Dice: 0.5570, F1: 0.5570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:24<00:00,  4.30it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00, 10.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.4556, IoU: 0.5468, Dice: 0.6371, F1: 0.6371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:24<00:00,  4.30it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.4336, IoU: 0.5255, Dice: 0.6330, F1: 0.6330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:24<00:00,  4.33it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.4178, IoU: 0.5602, Dice: 0.6594, F1: 0.6594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.31it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.4127, IoU: 0.5792, Dice: 0.6783, F1: 0.6783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.26it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00,  9.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.4011, IoU: 0.5611, Dice: 0.6384, F1: 0.6384\n",
            "✅ tversky_balanced: IoU=0.5792, Dice=0.6783\n",
            "\n",
            "======================================================================\n",
            "Training with tversky_precision: Tversky (precision focused)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6: 100%|██████████| 105/105 [00:24<00:00,  4.34it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.6146, IoU: 0.4263, Dice: 0.4950, F1: 0.4950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6: 100%|██████████| 105/105 [00:24<00:00,  4.37it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:03<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.5515, IoU: 0.4812, Dice: 0.5357, F1: 0.5357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6: 100%|██████████| 105/105 [00:24<00:00,  4.31it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00, 10.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.5277, IoU: 0.5416, Dice: 0.5969, F1: 0.5969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6: 100%|██████████| 105/105 [00:24<00:00,  4.30it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00, 10.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.5106, IoU: 0.4888, Dice: 0.5434, F1: 0.5434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6: 100%|██████████| 105/105 [00:24<00:00,  4.34it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00, 10.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.4942, IoU: 0.4907, Dice: 0.5315, F1: 0.5315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6: 100%|██████████| 105/105 [00:24<00:00,  4.37it/s]\n",
            "Evaluating: 100%|██████████| 27/27 [00:02<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.4845, IoU: 0.5444, Dice: 0.6071, F1: 0.6071\n",
            "✅ tversky_precision: IoU=0.5444, Dice=0.6071\n",
            "\n",
            "================================================================================\n",
            "LOSS FUNCTION ABLATION STUDY RESULTS\n",
            "================================================================================\n",
            "🏆 Best Loss Function: bce_dice_balanced\n",
            "   Description: BCE + Dice (balanced)\n",
            "   IoU: 0.6855, Dice: 0.7271, F1: 0.7271\n",
            "\n",
            "📉 Worst Loss Function: focal_high_gamma\n",
            "   Description: Focal Loss (high focus)\n",
            "   IoU: 0.4537, Dice: 0.3426, F1: 0.3426\n",
            "\n",
            "📊 Performance Gap: 0.2318 IoU difference\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-4155413325.py:599: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  box_plot = plt.boxplot(box_data, labels=metrics_for_box, patch_artist=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Loss function ablation study completed successfully!\n",
            "📊 Results saved to: /content/drive/MyDrive/Colab Notebooks/YOLO/YOLO12Result/loss_ablation_study/loss_ablation_results\n",
            "📈 Comprehensive analysis and visualizations generated\n",
            "\n",
            "================================================================================\n",
            "SUMMARY FOR PAPER - LOSS FUNCTION ANALYSIS\n",
            "================================================================================\n",
            "**Optimal Loss Function:** bce_dice_balanced\n",
            "- Performance: IoU=0.6855, Dice=0.7271\n",
            "- Improvement over BCE: +1.5% IoU\n",
            "- Configuration: BCE + Dice (balanced)\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}